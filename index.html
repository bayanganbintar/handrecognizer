<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Hand Gesture + Performance Monitor</title>
  <style>
    body {
      margin: 0;
      font-family: sans-serif;
      background: #111;
      color: #fff;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
    }
    video, canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
    }
    #perf-stats {
      position: fixed;
      bottom: 10px;
      left: 10px;
      background: rgba(0,0,0,0.7);
      color: #0f0;
      font-family: monospace;
      font-size: 14px;
      padding: 6px 10px;
      border-radius: 8px;
      z-index: 9999;
    }
  </style>
</head>
<body>
  <video id="webcam" autoplay muted playsinline></video>
  <canvas id="output_canvas"></canvas>

  <div id="perf-stats">
    <div>Latency: <span id="latency">--</span> ms</div>
    <div>FPS: <span id="fps">--</span></div>
  </div>

  <script type="module">
    import {
      HandLandmarker,
      FilesetResolver,
      DrawingUtils,
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("webcam");
    const canvas = document.getElementById("output_canvas");
    const ctx = canvas.getContext("2d");

    const latencyEl = document.getElementById("latency");
    const fpsEl = document.getElementById("fps");

    let handLandmarker;
    let runningMode = "VIDEO";
    let lastVideoTime = -1;
    let lastFPSUpdate = performance.now();
    let frameCounter = 0;
    let webcamRunning = false;

    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      return new Promise(resolve => {
        video.onloadedmetadata = () => resolve(video);
      });
    }

    async function init() {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );

      handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
          delegate: "GPU",
        },
        runningMode,
        numHands: 1,
      });

      await setupCamera();
      video.play();
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      webcamRunning = true;
      predictLoop();
    }

    async function predictLoop() {
      const start = performance.now();

      if (lastVideoTime !== video.currentTime) {
        lastVideoTime = video.currentTime;
        const results = handLandmarker.detectForVideo(video, start);

        const latency = performance.now() - start;
        latencyEl.textContent = latency.toFixed(1);

        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        if (results.landmarks) {
          for (const landmarks of results.landmarks) {
            DrawingUtils.drawConnectors(ctx, landmarks, HandLandmarker.HAND_CONNECTIONS, {
              color: "#00FF00",
              lineWidth: 2,
            });
            DrawingUtils.drawLandmarks(ctx, landmarks, { color: "#FF0000", lineWidth: 1 });
          }
        }
      }

      frameCounter++;
      const now = performance.now();
      if (now - lastFPSUpdate > 1000) {
        fpsEl.textContent = frameCounter;
        frameCounter = 0;
        lastFPSUpdate = now;
      }

      if (webcamRunning) requestAnimationFrame(predictLoop);
    }

    init();
  </script>
</body>
</html>
