<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Hand Gesture Sound</title>
    <style>
      body {
        font-family: sans-serif;
        text-align: center;
        margin-top: 3rem;
      }
      #gestureLabel {
        font-size: 2rem;
        font-weight: bold;
        margin-top: 1rem;
      }
    </style>
  </head>
  <body>
    <h1>Hand Gesture Music</h1>
    <button id="startBtn">Enable Webcam</button>
    <video id="webcam" autoplay playsinline style="display:none;"></video>
    <div id="gestureLabel"></div>

    <script type="module">
      import {
        HandLandmarker,
        FilesetResolver
      } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

      const video = document.getElementById("webcam");
      const gestureLabel = document.getElementById("gestureLabel");
      const startBtn = document.getElementById("startBtn");

      let handLandmarker;
      let gestureState = "";
      const ctx = new (window.AudioContext || window.webkitAudioContext)();

      const playNote = (frequency) => {
        const oscillator = ctx.createOscillator();
        oscillator.type = "sine";
        oscillator.frequency.setValueAtTime(frequency, ctx.currentTime);
        oscillator.connect(ctx.destination);
        oscillator.start();
        oscillator.stop(ctx.currentTime + 0.3); // short note
      };

      const detectPointing = (lm) =>
        lm[8].y < lm[6].y && [12, 16, 20].every((i) => lm[i].y > lm[i - 2].y);

      const detectClosed = (lm) =>
        [8, 12, 16, 20].every((i) => lm[i].y > lm[i - 2].y);

      async function initLandmarker() {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
        );
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath:
              "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
            delegate: "GPU"
          },
          runningMode: "VIDEO",
          numHands: 1
        });
      }

      async function startCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        await video.play();
        requestAnimationFrame(predictLoop);
      }

      async function predictLoop() {
        const now = performance.now();
        const res = handLandmarker.detectForVideo(video, now);
        if (res.landmarks.length) {
          const lm = res.landmarks[0];
          if (detectPointing(lm)) {
            if (gestureState !== "pointing") {
              gestureState = "pointing";
              gestureLabel.textContent = "ðŸ‘‰ Pointing";
              playNote(523); // C5
            }
          } else if (detectClosed(lm)) {
            if (gestureState !== "closed") {
              gestureState = "closed";
              gestureLabel.textContent = "âœŠ Closed Hand";
              playNote(392); // G4
            }
          } else {
            gestureState = "";
            gestureLabel.textContent = "";
          }
        } else {
          gestureState = "";
          gestureLabel.textContent = "";
        }
        requestAnimationFrame(predictLoop);
      }

      startBtn.onclick = async () => {
        startBtn.disabled = true;
        await initLandmarker();
        await startCamera();
      };
    </script>
  </body>
</html>
