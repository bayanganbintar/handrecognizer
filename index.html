<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Gesture Music</title>
  <style>
    body {
      font-family: sans-serif;
      text-align: center;
      margin-top: 2rem;
    }
    video {
      width: 100%;
      max-width: 400px;
      border-radius: 12px;
    }
    #gestureLabel {
      font-size: 1.8rem;
      font-weight: bold;
      margin-top: 1rem;
    }
  </style>
</head>
<body>
  <h1>Hand Gesture Music 0.3</h1>
  <button id="startBtn">Enable Webcam</button>
  <br />
  <video id="webcam" autoplay playsinline muted></video>
  <div id="gestureLabel"></div>

  <script type="module">
    import {
      HandLandmarker,
      FilesetResolver
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    const video = document.getElementById("webcam");
    const label = document.getElementById("gestureLabel");
    const startBtn = document.getElementById("startBtn");

    let handLandmarker;
    let gestureState = "";
    const ctx = new (window.AudioContext || window.webkitAudioContext)();

    const playNote = (frequency) => {
      const osc = ctx.createOscillator();
      osc.type = "sine";
      osc.frequency.value = frequency;
      osc.connect(ctx.destination);
      osc.start();
      osc.stop(ctx.currentTime + 0.3);
    };

    const isPointing = (lm) =>
      lm[8].y < lm[6].y &&
      [12, 16, 20].every((i) => lm[i].y > lm[i - 2].y);

    const isClosed = (lm) =>
      [8, 12, 16, 20].every((i) => lm[i].y > lm[i - 2].y);

    async function initLandmarker() {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );
      handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numHands: 1
      });
    }

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      await video.play();
      requestAnimationFrame(predictLoop);
    }

    async function predictLoop() {
      const ts = performance.now();
      const res = handLandmarker.detectForVideo(video, ts);
      if (res.landmarks.length > 0) {
        const lm = res.landmarks[0];
        if (isPointing(lm)) {
          if (gestureState !== "pointing") {
            gestureState = "pointing";
            label.textContent = "ðŸ‘‰ Pointing";
            playNote(523); // C5
          }
        } else if (isClosed(lm)) {
          if (gestureState !== "closed") {
            gestureState = "closed";
            label.textContent = "âœŠ Closed";
            playNote(392); // G4
          }
        } else {
          gestureState = "";
          label.textContent = "";
        }
      } else {
        gestureState = "";
        label.textContent = "";
      }
      requestAnimationFrame(predictLoop);
    }

    startBtn.onclick = async () => {
      startBtn.disabled = true;
      await initLandmarker();
      await startCamera();
    };
  </script>
</body>
</html>
